{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from StickerEnsemble import EnsembleStickerCube\n",
    "\n",
    "\n",
    "class Environment(EnsembleStickerCube):\n",
    "    \"\"\"\n",
    "    CUBE ENVIRONMENT\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Environment, self).__init__(randomize_representation = True)\n",
    "        self.valid_turns = [\"U\", \"U'\", \"R\", \"R'\", \"L\", \"L'\",\n",
    "                       \"F\", \"F'\", \"B\", \"B'\", \"D\", \"D'\"]\n",
    "        self.turns_thusfar = 0\n",
    "        \n",
    "    def make_start_state(self, number):\n",
    "        \"\"\"Resets the cubes. Generate a 'random' scramble. Return the image.\"\"\"\n",
    "        self.reset()\n",
    "        turn_arr = list(np.random.choice(self.valid_turns, size = number))\n",
    "        turns = \" \".join(turn_arr)\n",
    "        self.__call__(turns)\n",
    "        return self.visualize()\n",
    "    \n",
    "    def _get_reward(self):\n",
    "        cube = self.cubes[0]\n",
    "        sticker_list = cube.current_state\n",
    "        reward = 0\n",
    "        done = cube.is_solved()\n",
    "        if done:\n",
    "            reward += 20\n",
    "        for i in range(6):\n",
    "            side = sticker_list[(i*9):((i+1)*9)]\n",
    "            count = dict()\n",
    "            for stick in side:\n",
    "                if stick in count:\n",
    "                    count[stick]+=1\n",
    "                else:\n",
    "                    count[stick] = 1\n",
    "            reward += max((y for x, y in count.items()))\n",
    "        return reward, done\n",
    "    \n",
    "    def state_and_reward(self, current_state, picked_action):\n",
    "        \"\"\"\n",
    "        Should take the current state and the action and return the new state and the reward.\n",
    "        \"\"\"\n",
    "        self.turns_thusfar += 1\n",
    "            \n",
    "        actual_action = self.valid_turns[picked_action]\n",
    "        self.__call__(actual_action)\n",
    "        reward, done = self._get_reward()\n",
    "    \n",
    "        if self.turns_thusfar == 50 or done:\n",
    "            done = True\n",
    "            self.turns_thusfar = 0\n",
    "        return self.visualize(), reward, done\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "\n",
    "TRAJECTORY_LENGTH = 30 #Approximately 10 seconds\n",
    "MIDPOINTS = 2 #splits video data into trajectories of length above, but this determines the amount of overlap across trajectories\n",
    "\n",
    "EPSILON_PERTURBATIONS = False  #if we want the network to predict how to perturb LS vector.\n",
    "ITERATIONS = 100 #kinda like epochs?\n",
    "BATCH_SIZE = 10   #Might be the exact same thing as episodes, up for interpretation.\n",
    "EPISODES = 20     #How many trajectories to explore for a given job. Essentually to get a better estimate of the expected reward.\n",
    "DISCOUNT = 0.99   #how much to discount the reward\n",
    "ALPHA = 0.001     #learning rate?\n",
    "INPUT_SIZE = 3888\n",
    "#weight = torch.Tensor([0.5])\n",
    "\n",
    "class DPN(nn.Module):\n",
    "    \"\"\"AGENTS\"\"\"\n",
    "    def __init__(self, alpha, input_size, output_size):\n",
    "        super(DPN, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, input_size)\n",
    "        self.fc2 = nn.Linear(input_size, input_size)\n",
    "        self.fc3 = nn.Linear(input_size, input_size)\n",
    "        self.fc4 = nn.Linear(input_size, input_size)\n",
    "        self.fc5 = nn.Linear(input_size, output_size)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = T.tensor(x)\n",
    "        residual = x\n",
    "        h = F.leaky_relu(self.fc1(x)) + x\n",
    "        h = F.leaky_relu(self.fc2(h)) + h + x\n",
    "        h = F.leaky_relu(self.fc3(h)) +h\n",
    "        h = F.leaky_relu(self.fc4(h)) +h\n",
    "        h = F.softmax(self.fc5(h))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from random import random\n",
    "from scipy.stats import norm\n",
    "\n",
    "from torch.distributions import Categorical\n",
    "#from torch.distributions.independent import Independent\n",
    "#from torch.distributions.normal import Normal\n",
    "import torch\n",
    "\n",
    "DATA_FILE_NAME = \"trajectory_dict.pickle\"\n",
    "TRAJECTORY_LENGTH = 30 #Approximately 10 seconds\n",
    "MIDPOINTS = 2 #splits video data into trajectories of length above, but this determines the amount of overlap across trajectories\n",
    "\n",
    "EPSILON_PERTURBATIONS = False  #if we want the network to predict how to perturb LS vector.\n",
    "ITERATIONS = 1000 #kinda like epochs?\n",
    "BATCH_SIZE = 10   #Might be the exact same thing as episodes, up for interpretation.\n",
    "EPISODES = 20     #How many trajectories to explore for a given job. Essentually to get a better estimate of the expected reward.\n",
    "DISCOUNT = 0.99   #how much to discount the reward\n",
    "ALPHA = 3e-3     #learning rate?\n",
    "\n",
    "def curried_valuation(length_of_longest_trajectory):\n",
    "    '''\n",
    "    Given the length of the longest trajectory of a set of episodes;\n",
    "    returns the function that will compute the valuation of an episode array (while padding it)\n",
    "    Result intended to be used as  map(valuation, episodes_array) to return valuation of each episodes.\n",
    "    '''\n",
    "    def valuation(episode):\n",
    "        '''\n",
    "        returns the valuation of an episode (with padding)\n",
    "        input: [(s_0, a_0, r_0), ... ,(s_t, a_t, r_t)]         potentially t<length_of_longest_trajectory\n",
    "        output: [v_0, v_1, ... v_L]\n",
    "        '''\n",
    "\n",
    "        length = len(episode)\n",
    "        if length != length_of_longest_trajectory:\n",
    "            #If the episode isn't as long as the longest trajectory, pad it\n",
    "            episode.extend([(0,0,0) for y in range(length_of_longest_trajectory-length)]) #have to make sure the numbers line up correctly\n",
    "        out = np.zeros(len(episode))\n",
    "        x = [i[2] for i in episode] #rewards\n",
    "        out[-1] = x[-1]\n",
    "        for i in reversed(range(len(x)-1)): #go backwards\n",
    "            out[i] = x[i] + DISCOUNT*out[i+1] #this step valuation = reward + gamma*next_step_valuation\n",
    "        #assert x.ndim >= 1\n",
    "        return out\n",
    "    return valuation\n",
    "\n",
    "def weights_init_uniform_rule(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        # get the number of the inputs\n",
    "        n = m.in_features\n",
    "        y = 1.0/np.sqrt(n)\n",
    "        m.weight.data.uniform_(-y, y)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "\n",
    "class DpnTraining:\n",
    "    def __init__(self, INPUT_SIZE, policy_net):\n",
    "        '''\n",
    "        INPUT_SIZE = size and shape from the environment's output for a state  TODO\n",
    "        OUTPUT_SIZE = number of possible actions                               TODO\n",
    "        Probably include stuff to interact with the environment after inputting a class\n",
    "        all caps words are hyperparameters you would set.\n",
    "        '''\n",
    "        self.env = Environment()\n",
    "\n",
    "        # Define the network\n",
    "        self.network = policy_net(ALPHA, 3888, 12)\n",
    "        self.network.apply(weights_init_uniform_rule)\n",
    "        # logging\n",
    "        self.eps = np.finfo(np.float32).eps.item()\n",
    "        self.rewards = []\n",
    "        self.variance = []\n",
    "        self.rewards_last = []\n",
    "        self.variance_last = []\n",
    "\n",
    "\n",
    "    def train(self, ITERATIONS):\n",
    "        optimizer = torch.optim.Adam(self.network.parameters(), lr = ALPHA) #This is roughly based on some pytorch examples. We use this to update weights of the model.\n",
    "        x = ITERATIONS\n",
    "        #[int(round(x,0)) for x in np.linspace(0,25, ITERATIONS)+1]\n",
    "        cnt = 0 \n",
    "        for i in range(x+1):\n",
    "            cnt += 1 \n",
    "            first_frame = self.env.make_start_state(i) #this would be a list of starting states\n",
    "            jobs = [first_frame] #TODO: Coerce job variable to appropriate pytorch type. Necessary due to environment not set up to handle processing different trajectories.\n",
    "            self.train_on_jobs(jobs, optimizer)\n",
    "            print(\"Iteration \"+str(i+1)+\" Completed with reward: \" + str(self.rewards[-1]) + \" Variance of :\" + str(self.variance[-1]))\n",
    "            print(\"Average last avg reward: \" + str(self.rewards_last[-1]) + \" last variance avg: \" + str(self.variance_last[-1]))\n",
    "            if cnt % 100 == 0: \n",
    "                torch.save(self.network.state_dict(), location)\n",
    "\n",
    "\n",
    "\n",
    "    def fix_obs(self, observation):\n",
    "        observation = observation.flatten()\n",
    "        observation = observation/255\n",
    "        observation = T.from_numpy(observation.astype(np.float)).float()\n",
    "        return observation\n",
    "\n",
    "    def forward(self, state):\n",
    "        '''\n",
    "        The forward pass of the network on the given state. Returns the output probabilites for taking the OUTPUT_SIZE probabilites\n",
    "        might already be defined from the initialization after defining your model\n",
    "        '''\n",
    "        state = self.fix_obs(state)\n",
    "        probs = self.network(state)\n",
    "        return probs\n",
    "\n",
    "\n",
    "    def trajectory(self, current_state):\n",
    "        '''\n",
    "        Maybe this implementation doesn't utilize GPUs very well, but I have no clue or not.\n",
    "        Final output looks like:\n",
    "        [(s_0, a_0, r_0), ..., (s_L, a_L, r_l)]\n",
    "        '''\n",
    "        output_history = []\n",
    "        while True:\n",
    "            probs = self.forward(current_state)\n",
    "            distribution = Categorical(probs)\n",
    "            picked_action = distribution.sample()\n",
    "            action = picked_action.detach()\n",
    "            #print(action)\n",
    "            new_state, reward, done = self.env.state_and_reward(current_state, action) #Get the reward and the new state that the action in the environment resulted in. None if action caused death. TODO build in environment\n",
    "            #Attempting this\n",
    "            lg = distribution.log_prob(action)\n",
    "            output_history.append( (current_state, action, reward, lg) )\n",
    "            if done: #essentially, you died or finished your trajectory\n",
    "                break\n",
    "            else:\n",
    "                current_state = new_state\n",
    "        return output_history\n",
    "\n",
    "    def train_on_jobs(self,jobset, optimizer):\n",
    "        '''\n",
    "        Training from a batch. Kinda presume the batch is a set of starting states not sure how you have the implemented states (do they include actions internally?)\n",
    "        example shape of episode_array\n",
    "        [\n",
    "        [1, 2, 3, 4, 5],\n",
    "        [1, 2, 3, 4, 5, 6, 7],\n",
    "        [1, 2, 3]\n",
    "        ]\n",
    "        '''\n",
    "        #optimizer.zero_grad()#Basically start gradient or how you'll change weights out at 0 but with the shape or whatever you need to update the weights through addition. TODO figure out how this thing should look\n",
    "        for job_start in jobset:\n",
    "            optimizer.zero_grad()\n",
    "            #episode_array is going to be an array of length N containing trajectories [(s_0, a_0, r_0), ..., (s_L, a_L, r_0)]\n",
    "            episode_array = [self.trajectory(job_start) for x in range(EPISODES)]\n",
    "            # Now we need to make the valuations\n",
    "            #temp\n",
    "            longest_trajectory = max(len(episode) for episode in episode_array)\n",
    "            valuation_fun = curried_valuation(longest_trajectory)\n",
    "            cum_values = np.array([valuation_fun(ep) for ep in episode_array]) #should be a EPISODESxlength sized\n",
    "            #Compute the baseline valuations.\n",
    "            baseline_array = np.array([sum(cum_values[:,i])/EPISODES for i in range(longest_trajectory)]) #Probably defeats the purpose of numpy, but we're essentially trying to sum each valuation array together, and then divide by the number of episodes\n",
    "            avg = baseline_array[0]\n",
    "            var = [np.sqrt(sum(np.square(cum_values[:,i]-baseline_array[i]))/EPISODES) for i in range(longest_trajectory)]\n",
    "            #log\n",
    "            self.rewards.append(avg)\n",
    "            self.variance.append(var[0])\n",
    "            self.variance_last.append(var[-1])\n",
    "            self.rewards_last.append(baseline_array[-1])\n",
    "            #policy updates\n",
    "            for i in range(EPISODES): #swapped two for loops\n",
    "                for t in range(longest_trajectory):\n",
    "                    try:\n",
    "                        state, action, reward, log_pro= episode_array[i][t]\n",
    "                    except ValueError: #this occurs when the trajectory is over.\n",
    "                        pass\n",
    "                    if var[t] <1e-4:\n",
    "                        varry = 1e-4\n",
    "                    else:\n",
    "                        varry = var[t]\n",
    "                    #first two products are scalars, final is scalar multiplication of computed gradients on the NN\n",
    "                    if i ==0 and t == 0:\n",
    "                        loss = -(cum_values[i][t]-baseline_array[t])/(varry + self.eps) * log_pro #This is what it should look like in pytorch. Added negative on recommendation of pytorch documentation\n",
    "                    else:\n",
    "                        loss += -(cum_values[i][t]-baseline_array[t])/(varry + self.eps)*log_pro\n",
    "            loss.backward() #Compute the total cumulated gradient thusfar through our big-ole sum of losses\n",
    "            optimizer.step() #Actually update our network weights. The connection between loss and optimizer is \"behind the scenes\", but recall that it's dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13522\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 1 Completed with reward: 741.5671450871705 Variance of :31.33594842367577\n",
      "Average last avg reward: 19.35 last variance avg: 1.878163997099295\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 2 Completed with reward: 1362.2328448417509 Variance of :4.012312525796688\n",
      "Average last avg reward: 37.0 last variance avg: 5.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 3 Completed with reward: 1362.2328448417509 Variance of :4.012312525796688\n",
      "Average last avg reward: 37.0 last variance avg: 5.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 4 Completed with reward: 1006.8375499722837 Variance of :2.4114403564135496\n",
      "Average last avg reward: 27.5 last variance avg: 2.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 5 Completed with reward: 799.8130916931133 Variance of :1.2280108033500596\n",
      "Average last avg reward: 20.5 last variance avg: 1.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 6 Completed with reward: 918.112782138354 Variance of :0.40933693445009567\n",
      "Average last avg reward: 24.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 7 Completed with reward: 829.5865037179225 Variance of :2.4276517201541874\n",
      "Average last avg reward: 20.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 8 Completed with reward: 1363.2252919092446 Variance of :4.052840935148652\n",
      "Average last avg reward: 32.0 last variance avg: 0.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 9 Completed with reward: 789.9878657249263 Variance of :0.8024625051593262\n",
      "Average last avg reward: 20.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 10 Completed with reward: 740.2662676434958 Variance of :0.40123125257986203\n",
      "Average last avg reward: 20.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 11 Completed with reward: 918.3112715518524 Variance of :1.2117994396095355\n",
      "Average last avg reward: 23.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 12 Completed with reward: 829.5865037179225 Variance of :0.004052840935230506\n",
      "Average last avg reward: 20.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 13 Completed with reward: 740.5640017637437 Variance of :0.4052840935149789\n",
      "Average last avg reward: 19.0 last variance avg: 0.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 14 Completed with reward: 730.8380205023066 Variance of :1.6130306921890563\n",
      "Average last avg reward: 18.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 15 Completed with reward: 957.8106648380987 Variance of :2.8329358136688256\n",
      "Average last avg reward: 24.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 16 Completed with reward: 760.4129431136163 Variance of :0.3971784116445746\n",
      "Average last avg reward: 19.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 17 Completed with reward: 681.4141565411238 Variance of :0.39717841164451784\n",
      "Average last avg reward: 17.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 18 Completed with reward: 740.6632464704933 Variance of :0.41744261632049984\n",
      "Average last avg reward: 18.5 last variance avg: 1.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 19 Completed with reward: 750.6869618521793 Variance of :2.2737367544323206e-13\n",
      "Average last avg reward: 18.0 last variance avg: 0.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 20 Completed with reward: 721.1120392408691 Variance of :0.4052840935150357\n",
      "Average last avg reward: 17.0 last variance avg: 0.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 21 Completed with reward: 789.9878657249265 Variance of :1.6130306921892836\n",
      "Average last avg reward: 20.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 22 Completed with reward: 809.9360517815485 Variance of :1.6170835331243438\n",
      "Average last avg reward: 19.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 23 Completed with reward: 779.9641503432412 Variance of :1.2199051214794283\n",
      "Average last avg reward: 20.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 24 Completed with reward: 819.662033042986 Variance of :0.40123125257952097\n",
      "Average last avg reward: 20.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 25 Completed with reward: 701.4615873044952 Variance of :0.4052840935149788\n",
      "Average last avg reward: 16.0 last variance avg: 0.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 26 Completed with reward: 651.8392339298141 Variance of :0.8024625051594967\n",
      "Average last avg reward: 16.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 27 Completed with reward: 789.9878657249265 Variance of :0.7943568232889788\n",
      "Average last avg reward: 20.0 last variance avg: 2.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 28 Completed with reward: 701.0646084774974 Variance of :0.4133897753849283\n",
      "Average last avg reward: 18.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 29 Completed with reward: 770.1389243750539 Variance of :0.8024625051595534\n",
      "Average last avg reward: 20.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 30 Completed with reward: 859.062181622483 Variance of :0.4133897753850988\n",
      "Average last avg reward: 22.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 31 Completed with reward: 612.3398406435679 Variance of :2.2737367544323206e-13\n",
      "Average last avg reward: 15.0 last variance avg: 0.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 32 Completed with reward: 750.5877171454296 Variance of :0.8065153460946136\n",
      "Average last avg reward: 18.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 33 Completed with reward: 760.015964286619 Variance of :0.39717841164451784\n",
      "Average last avg reward: 21.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 34 Completed with reward: 691.2393825093106 Variance of :0.8065153460943293\n",
      "Average last avg reward: 17.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 35 Completed with reward: 691.4378719228094 Variance of :0.814621027964904\n",
      "Average last avg reward: 16.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 36 Completed with reward: 809.7375623680495 Variance of :1.6089778512541102\n",
      "Average last avg reward: 20.5 last variance avg: 1.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 37 Completed with reward: 710.989079152434 Variance of :0.7943568232891492\n",
      "Average last avg reward: 18.0 last variance avg: 2.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 38 Completed with reward: 730.6395310888074 Variance of :0.008105681870119952\n",
      "Average last avg reward: 19.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 39 Completed with reward: 691.3386272160599 Variance of :0.008105681870119952\n",
      "Average last avg reward: 17.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 40 Completed with reward: 780.0633950499904 Variance of :2.0183147857040353\n",
      "Average last avg reward: 20.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 41 Completed with reward: 809.7375623680498 Variance of :0.7984096642242662\n",
      "Average last avg reward: 20.5 last variance avg: 1.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 42 Completed with reward: 730.937265209056 Variance of :1.617083533124287\n",
      "Average last avg reward: 17.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 43 Completed with reward: 800.0115811066123 Variance of :0.40123125257986203\n",
      "Average last avg reward: 19.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 44 Completed with reward: 819.9597671632339 Variance of :1.2077465986742484\n",
      "Average last avg reward: 19.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 45 Completed with reward: 641.9147632548775 Variance of :0.3971784116444609\n",
      "Average last avg reward: 16.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 46 Completed with reward: 681.5134012478733 Variance of :0.40933693445009567\n",
      "Average last avg reward: 16.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 47 Completed with reward: 829.4872590111733 Variance of :3.410605131648481e-13\n",
      "Average last avg reward: 21.0 last variance avg: 0.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 48 Completed with reward: 760.2144537001177 Variance of :1.2077465986741913\n",
      "Average last avg reward: 20.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 49 Completed with reward: 829.3880143044235 Variance of :0.004052840935230506\n",
      "Average last avg reward: 21.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 50 Completed with reward: 681.2156671276252 Variance of :2.018314785703921\n",
      "Average last avg reward: 18.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 51 Completed with reward: 799.4161128661161 Variance of :0.4093369344498683\n",
      "Average last avg reward: 22.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 52 Completed with reward: 641.9147632548775 Variance of :0.3971784116444609\n",
      "Average last avg reward: 16.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 53 Completed with reward: 730.6395310888075 Variance of :1.1368683772161603e-13\n",
      "Average last avg reward: 19.0 last variance avg: 0.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 54 Completed with reward: 701.0646084774976 Variance of :1.2077465986741345\n",
      "Average last avg reward: 18.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 55 Completed with reward: 829.4872590111729 Variance of :0.8024625051593262\n",
      "Average last avg reward: 21.0 last variance avg: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 56 Completed with reward: 760.3136984068674 Variance of :0.40933693445009567\n",
      "Average last avg reward: 19.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 57 Completed with reward: 641.8155185481281 Variance of :0.4012312525795778\n",
      "Average last avg reward: 16.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 58 Completed with reward: 622.1650666117541 Variance of :0.40123125257974834\n",
      "Average last avg reward: 15.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 59 Completed with reward: 918.4105162586018 Variance of :1.207746598674305\n",
      "Average last avg reward: 23.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 60 Completed with reward: 691.0408930958123 Variance of :0.8146210279647902\n",
      "Average last avg reward: 18.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 61 Completed with reward: 721.0127945341196 Variance of :1.2117994396095924\n",
      "Average last avg reward: 17.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 62 Completed with reward: 710.8898344456845 Variance of :0.012158522805464143\n",
      "Average last avg reward: 18.5 last variance avg: 1.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 63 Completed with reward: 661.6644598980008 Variance of :0.40123125257974834\n",
      "Average last avg reward: 16.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 64 Completed with reward: 770.2381690818034 Variance of :0.004052840935230506\n",
      "Average last avg reward: 19.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 65 Completed with reward: 878.9111229723554 Variance of :1.2158522805445386\n",
      "Average last avg reward: 22.0 last variance avg: 0.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 66 Completed with reward: 819.2650542159884 Variance of :0.40123125257969144\n",
      "Average last avg reward: 22.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 67 Completed with reward: 770.5359032020515 Variance of :1.6130306921892836\n",
      "Average last avg reward: 18.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 68 Completed with reward: 819.5627883362362 Variance of :0.40528409351463773\n",
      "Average last avg reward: 21.0 last variance avg: 0.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 69 Completed with reward: 631.8910478731921 Variance of :0.8146210279647902\n",
      "Average last avg reward: 16.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 70 Completed with reward: 839.7094638063572 Variance of :0.4093369344499251\n",
      "Average last avg reward: 19.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 71 Completed with reward: 760.3136984068669 Variance of :1.203693757738961\n",
      "Average last avg reward: 19.5 last variance avg: 1.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 72 Completed with reward: 681.1164224208757 Variance of :2.0142619447688617\n",
      "Average last avg reward: 18.5 last variance avg: 1.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 73 Completed with reward: 740.663246470493 Variance of :2.014261944768805\n",
      "Average last avg reward: 18.5 last variance avg: 1.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 74 Completed with reward: 641.5177844278803 Variance of :0.4052840935148651\n",
      "Average last avg reward: 18.0 last variance avg: 0.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 75 Completed with reward: 721.0127945341197 Variance of :1.2117994396095926\n",
      "Average last avg reward: 17.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 76 Completed with reward: 691.040893095812 Variance of :1.6170835331244573\n",
      "Average last avg reward: 18.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 77 Completed with reward: 819.4635436294873 Variance of :0.3931255707093442\n",
      "Average last avg reward: 21.5 last variance avg: 1.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 78 Completed with reward: 799.8130916931134 Variance of :0.4093369344498683\n",
      "Average last avg reward: 20.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 79 Completed with reward: 799.7138469863645 Variance of :1.2077465986741913\n",
      "Average last avg reward: 21.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 80 Completed with reward: 691.1401378025613 Variance of :0.8024625051595535\n",
      "Average last avg reward: 18.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 81 Completed with reward: 770.1389243750543 Variance of :0.8105681870297303\n",
      "Average last avg reward: 20.0 last variance avg: 0.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 82 Completed with reward: 849.3362003610449 Variance of :3.226061384378397\n",
      "Average last avg reward: 21.0 last variance avg: 2.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 83 Completed with reward: 730.6395310888075 Variance of :1.604925010318823\n",
      "Average last avg reward: 19.0 last variance avg: 2.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 84 Completed with reward: 740.5640017637442 Variance of :0.3971784116446316\n",
      "Average last avg reward: 19.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 85 Completed with reward: 779.8649056364914 Variance of :1.2077465986740774\n",
      "Average last avg reward: 21.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 86 Completed with reward: 681.2156671276248 Variance of :0.4052840935148083\n",
      "Average last avg reward: 18.0 last variance avg: 0.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 87 Completed with reward: 750.1907383184323 Variance of :0.798409664224323\n",
      "Average last avg reward: 20.5 last variance avg: 1.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 88 Completed with reward: 592.3916545869458 Variance of :1.61708353312423\n",
      "Average last avg reward: 15.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 89 Completed with reward: 839.4117296861089 Variance of :0.38907272977411367\n",
      "Average last avg reward: 21.0 last variance avg: 2.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 90 Completed with reward: 770.0396796683045 Variance of :1.6089778512537691\n",
      "Average last avg reward: 20.5 last variance avg: 1.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 91 Completed with reward: 671.4896858661876 Variance of :0.80246250515944\n",
      "Average last avg reward: 17.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 92 Completed with reward: 720.9135498273699 Variance of :0.39717841164463147\n",
      "Average last avg reward: 18.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 93 Completed with reward: 710.9890791524338 Variance of :1.613030692189113\n",
      "Average last avg reward: 18.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 94 Completed with reward: 789.8886210181767 Variance of :1.617083533124173\n",
      "Average last avg reward: 20.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 95 Completed with reward: 908.2875561701667 Variance of :0.8105681870299009\n",
      "Average last avg reward: 24.0 last variance avg: 0.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 96 Completed with reward: 760.4129431136163 Variance of :0.3971784116445746\n",
      "Average last avg reward: 19.0 last variance avg: 1.0\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "Iteration 97 Completed with reward: 721.0127945341194 Variance of :0.40933693445015246\n",
      "Average last avg reward: 17.5 last variance avg: 0.5\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n",
      "HALFIES\n"
     ]
    }
   ],
   "source": [
    "dpn = DpnTraining(INPUT_SIZE = 3888, policy_net = DPN)\n",
    "dpn.train(ITERATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment()\n",
    "agent = Agent(alpha=0.3,beta=0.3, input_dims = 3888, output_dims = len([\"U\", \"U'\", \"R\", \"R'\", \"L\", \"L'\",\n",
    "                       \"F\", \"F'\", \"B\", \"B'\", \"D\", \"D'\"]))\n",
    "\n",
    "n_games = 50000\n",
    "run_name = \"please_finish_by_morning\"\n",
    "import os\n",
    "if not os.path.exists(run_name):\n",
    "    os.makedirs(run_name)\n",
    "#print(agent.actor.state_dict())\n",
    "\n",
    "x = [int(round(x,0)) for x in np.linspace(0,25, n_games)+1]\n",
    "\n",
    "run_name = \"FAST\"\n",
    "import os\n",
    "if not os.path.exists(run_name):\n",
    "    os.makedirs(run_name)\n",
    "\n",
    "scores = []\n",
    "for i in x:\n",
    "    done = False\n",
    "    observation = env.make_start_state(i)\n",
    "    score = 0\n",
    "    agent.actor.optimizer.zero_grad()\n",
    "    while not done:\n",
    "        action = agent.choose_action(observation)\n",
    "        observation_, reward, done = env.state_and_reward(observation ,action)\n",
    "        actor_loss = agent.learn(observation, reward, observation_, done)\n",
    "        if score == 0:\n",
    "            actor_total_loss = actor_loss\n",
    "        else:\n",
    "            actor_total_loss += actor_loss\n",
    "        score += reward\n",
    "        observation = observation_\n",
    "    actor_loss = actor_loss\n",
    "    actor_loss.backward()\n",
    "    agent.actor.optimizer.step()\n",
    "    if i%20 == 0:\n",
    "        agent.update_critic_target()\n",
    "\n",
    "            \n",
    "    if i % 1000 == 0:\n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            avg = np.mean(scores[-1000:])\n",
    "            location = \"./\"+run_name+ \"/\"+str(avg)+\"_avg_\"+str(i)+\"_ngames.pt\"\n",
    "            torch.save(agent.actor.state_dict(), location)\n",
    "    scores.append(score)\n",
    "\n",
    "    avg_score = np.mean(scores[-100:])\n",
    "    print('episode ', i, 'score %.1f' % score,\n",
    "            'average score %.1f' % avg_score, \"    avg single score: \", score/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [i+1 for i in range(n_games-100)]\n",
    "plt.plot(scores)\n",
    "location = run_name + \"/\" + run_name\n",
    "plt.savefig(location +\"train.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = scores\n",
    "y2 = []\n",
    "mean = lambda x: sum(x)/len(x)\n",
    "for i in range(len(y1)):\n",
    "    if i < 100:\n",
    "        pass\n",
    "    else:\n",
    "        avg = mean(y1[(i-100):i])\n",
    "        y2.append(avg)\n",
    "        \n",
    "plt.plot(y2)\n",
    "#plt.show()\n",
    "plt.savefig(location+\"train_smooth.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
